{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68274b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from vlmeval.dataset.utils import mathvista\n",
    "\n",
    "model_name = 'R1-VL-2B'\n",
    "choice = 4\n",
    "dataset = 'MathVista_MINI'\n",
    "judge = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd0fc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join('outputs', model_name, f'{model_name}_{dataset}_{judge}.xlsx')\n",
    "df_greedy = pd.read_excel(file_path)\n",
    "# CoT results aggregation\n",
    "df_list = [pd.DataFrame() for _ in range(2*choice)]\n",
    "for i in range(choice):\n",
    "    file_path = os.path.join('outputs', model_name, f'{model_name}_{dataset}_False_{i}_{judge}.xlsx')\n",
    "    df_list[i] = pd.read_excel(file_path)\n",
    "for i in range(choice):\n",
    "    file_path = os.path.join('outputs', model_name, f'{model_name}_{dataset}_True_{i}_{judge}.xlsx')\n",
    "    df_list[i+choice] = pd.read_excel(file_path)\n",
    "summary = df_list[0].copy(deep=True)\n",
    "summary['length'] = summary['length'].astype(float)\n",
    "summary = summary.rename(columns={'prediction': 'ref'})\n",
    "majority = df_list[choice].copy(deep=True)\n",
    "majority['length'] = majority['length'].astype(float)\n",
    "majority = majority.rename(columns={'prediction': 'ref'})\n",
    "CoT_correct = 0\n",
    "maj_correct = 0\n",
    "greedy_correct = 0\n",
    "for rows in zip(*[df.iterrows() for df in df_list]):\n",
    "    index = rows[0][0]\n",
    "    res_list = [rows[x][1].res for x in range(choice)]\n",
    "    maj_res_list = [rows[x+choice][1].res for x in range(choice)]\n",
    "    confidence_list = [rows[x][1].confidence for x in range(choice)]\n",
    "    length_list = [rows[x][1].length for x in range(choice)]\n",
    "    maj_length_list = [rows[x+choice][1].length for x in range(choice)]\n",
    "    summary.at[index, 'length'] = sum(length_list)/choice\n",
    "    majority.at[index, 'length'] = sum(maj_length_list)/choice\n",
    "    aggr = {}\n",
    "    for j, key in enumerate(res_list):\n",
    "        aggr[key] = aggr.get(key, 0) + confidence_list[j]\n",
    "    best_answer = max(aggr, key=aggr.get)\n",
    "    summary.at[index, 'res'] = best_answer\n",
    "    vote = {}\n",
    "    for j, key in enumerate(maj_res_list):\n",
    "        vote[key] = vote.get(key, 0) + 1\n",
    "    most_answer = max(vote, key=vote.get)\n",
    "    majority.at[index, 'res'] = most_answer\n",
    "    summary.at[index, 'confidence'] = aggr[best_answer]\n",
    "    if mathvista.post_check(summary.iloc[index], prefetch=False):\n",
    "        summary.at[index, 'log'] = 'Correct'\n",
    "        CoT_correct += 1\n",
    "    else:\n",
    "        summary.at[index, 'log'] = 'Wrong'\n",
    "    if mathvista.post_check(majority.iloc[index], prefetch=False):\n",
    "        majority.at[index, 'log'] = 'Correct'\n",
    "        maj_correct += 1\n",
    "    else:\n",
    "        majority.at[index, 'log'] = 'Wrong'\n",
    "    if mathvista.post_check(df_greedy.iloc[index], prefetch=False):\n",
    "        df_greedy.at[index, 'log'] = 'Correct'\n",
    "        greedy_correct += 1\n",
    "    else:\n",
    "        df_greedy.at[index, 'log'] = 'Wrong'\n",
    "    select = []\n",
    "    for k, key in enumerate(res_list):\n",
    "        if best_answer == key:\n",
    "            select.append(k+1)\n",
    "    summary.at[index, 'ref'] = select\n",
    "    maj_select = []\n",
    "    for k, key in enumerate(maj_res_list):\n",
    "        if most_answer == key:\n",
    "            maj_select.append(k+1)\n",
    "    majority.at[index, 'ref'] = maj_select\n",
    "print('CoT Accuracy: ', CoT_correct/len(summary))\n",
    "print('Majority Vote Accuracy: ', maj_correct/len(majority))\n",
    "print('Greedy Accuracy: ', greedy_correct/len(df_greedy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86127f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(f'{model_name}_{dataset}_{choice}_{judge}.xlsx', engine='openpyxl') as writer:\n",
    "    df_greedy.to_excel(writer, sheet_name=f'Greedy', index=False)\n",
    "    summary.to_excel(writer, sheet_name=f'CoT-Aggregation', index=False)\n",
    "    majority.to_excel(writer, sheet_name=f'Majority-Vote', index=False)\n",
    "    for i in range(choice):\n",
    "        df_list[i].to_excel(writer, sheet_name=f'CoT-{i+1}', index=False)\n",
    "        df_list[i+choice].to_excel(writer, sheet_name=f'Majority-{i+1}', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtenv3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
